\documentclass[11pt]{article}

\usepackage{amsmath, amssymb, amsthm} % ams packages %amsfonts is loaded by amssymb
\usepackage[all,warning]{onlyamsmath}
\usepackage{graphics, graphicx} % graphics packages


\usepackage[margin=1.2in]{geometry} % more reasonable margins
\usepackage{booktabs} % prettier tables
\usepackage{units} % prettier fractions (?)

% Small sections of multiple columns
\usepackage{multicol}

\usepackage{bm}

\usepackage{natbib}

\usepackage{tikz} % make graphics in latex
\usetikzlibrary{shapes,decorations}
\usetikzlibrary{arrows}
\usepackage{pgfplots} % to make plots in latex
\pgfplotsset{compat=newest} % compatibility issue
\usepackage{enumitem, comment}

% formatting
\usepackage{fancyhdr} % for changing headers and footers
\usepackage{url} % url 
\usepackage[normalem]{ulem}
\usepackage{color} % colored text + names %deprecated?
\usepackage{algorithm}
\usepackage{algorithmic}

% hyperlink in the document
\usepackage{hyperref} % must be the last package loaded

\usepackage{comment}

\usepackage{parskip}

\usepackage{xcolor}
\definecolor{dark-red}{rgb}{0.4,0.15,0.15}
\definecolor{dark-blue}{rgb}{0.15,0.15,0.4}
\definecolor{medium-blue}{rgb}{0,0,0.5}
\hypersetup{
   colorlinks, linkcolor={dark-blue},
   citecolor={dark-blue}, urlcolor={medium-blue}
}

% notations
\newcommand{\one}{\ensuremath{\mathbf{1}}}
\newcommand{\zero}{\ensuremath{\mathbf{0}}}
\newcommand{\prob}{\ensuremath{\mathbf{P}}}
\newcommand{\expec}{\ensuremath{\mathbf{E}}}
\newcommand{\ind}{\ensuremath{\mathbf{I}}}
\newcommand{\reals}{\ensuremath{\mathbb{R}}}
\newcommand{\naturals}{\ensuremath{\mathbb{N}}}
\newcommand{\defeq}{\ensuremath{\triangleq}}
\newcommand{\sP}{\ensuremath{\mathsf{P}}}
\newcommand{\sQ}{\ensuremath{\mathsf{Q}}}
\newcommand{\sE}{\ensuremath{\mathsf{E}}}

\newcommand{\mbf}[1]{{\boldsymbol{\mathbf{#1}}}}
\renewcommand{\bm}{\mbf}

\newcommand{\FIXME}[1]{\textcolor{red}{[#1]}}



% environments
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}
\newtheorem{remark}{Remark}
\newtheorem{definition}{Definition}
\newtheorem{assumption}{Assumption}


\title{Understanding the Bayesian GAN: \\theoretical and practical advances}
\author{Andrew Gordon Wilson}

\begin{document}
\maketitle

\section{Introduction}

GANs have been exceptionally impactful for learning rich distributions over images, audio, and data which are hard to model with an explicit likelihood.  By exploring an expressive posterior over the weights of the generator and disciminator, the newly introduced Bayesian GAN \citep{saatchiwilson2017} avoids mode-collapse, produces interpretable and diverse candidate samples, and provides state-of-the-art quantitative results for semi-supervised learning, while requiring minimal intervention. 

Here I propose steps for a follow-up project, with the potential to make fundamental contributions to our understanding of probabilistic generative models.

\begin{enumerate}
\item Re-implement the Bayesian GAN in PyTorch.  As a check, use this code to reproduce some of the results in \citet{saatchiwilson2017}.  Make sure the code is robust, simple, and easy to use.
\item Scalability: it is straightforward to entirely parallelize and distribute the computations over both J and M in Algorithm 1 of the Bayesian GAN, so that it is \emph{as efficient} as a standard DCGAN!  We should pursue this and do a runtime comparison.
\item The Bayesian GAN did not require nearly as much intervention as the DCGAN. This is possibly due to the prior on the weights.  Presently, we use a very simple, fixed, spherical Gaussian prior for the weights.  Explore the empirical effects of using Gaussian mixture distributions, and  other interesting priors for the weights, learning the parameters through marginal likelihood optimization or cross-validation.  \citet{fortunato2017bayesian} for instance, provides an example of tuning a Gaussian mixture prior for weights of a Bayesian LSTM.  I expect that the prior specification will make a major difference in terms of predictive performance, and could achieve state of the art on several benchmarks.  
\item It would also be really exciting to explore sparsity inducing priors.  It may be possible to achieve highly efficient inference and also somewhat side-step architecture design by having clever prior distributions over the weight parameters.
\item Interestingly, the standard GAN can be viewed as a maximum-likelihood analogue of our proposed probabilistic GAN: if one uses improper uniform priors for $\theta_g$ and $\theta_d$, and performs iterative SGD optimization instead of posterior sampling over Eq. (1) and (2) for unsupervised learning, then the local optima will be the same as for Algorithm 1 of \citep{goodfellow2014generative}.  Recent work, such as f-GANs \citep{nowozin2016} and Wasserstein GANs \citep{arjovsky2017wasserstein}, can be seen as modifying this maximum likelihood training objective for various desirable properties.  Various different priors within our probabilistic framework, in combination with alternating MAP optimization (instead of full inference, as we pursue), can also be used as a mechanism to modify the training objective for standard GANs.  Show how different priors, with MAP, can be used to recover recent GAN variants.  Such a result would provide a powerful probabilistic perspective on recent developments, and a natural mechanism for further adaptation, and training of hyperparameters.
\item The inference procedure in \citet{saatchiwilson2017} alternately samples from conditional posteriors over $\theta_d$ and $\theta_g$, in a procedure that resembles Gibbs sampling.  However, we do not know about the joint distribution that corresponds to those conditionals, so we cannot automatically apply Gibbs sampling theory to prove that the procedure will converge to a stationary distribution.  In other words, we need to know under what conditions the Markov chain produced by iteratively sampling from the Markov kernels in (1) and (2) would have a stationary distribution.   To start, one can think about applying machinery for general Markov chains, such as Harris recurrence relations, for convergence guarantees.  Ideally we want to prove convergence under the most relaxed conditions.
\item The alternative approach to Bayesian marginalization in implicit generative models often involves variational methods and density ratio estimation \citep{tran2017deep, mohamed2016learning}.  It would be interesting to explicitly enumerate the very specific differences and similarities between these approaches.
\end{enumerate}

%, and can be remedied with fully probabilistic inference. 
 
 %\citet{goodfellow2014generative} propose to learn the discimin
   
 




\bibliographystyle{apalike}
\bibliography{mbibnew}
\end{document}


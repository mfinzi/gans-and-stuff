{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from bgan.datasets import make_semi_dataset_from_tensors, make_batch_generator\n",
    "from bgan.synth_utils import js_div, kl_div, pca\n",
    "from bgan.priors import FactorizedNormalPrior\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "x_train, y_train = trainset.train_data.float() / 255, trainset.train_labels\n",
    "x_test, y_test = testset.test_data.float() / 255, testset.test_labels\n",
    "x_test = x_test[:, None, :, :].float()\n",
    "y_test = y_test.numpy()\n",
    "\n",
    "labeled, unlabeled = make_semi_dataset_from_tensors(x_train[:, None, :, :].float(), \n",
    "                                                    y_train[:, None], labeled_fraction=0.1)\n",
    "\n",
    "# labeledloader = torch.utils.data.DataLoader(labeled, batch_size=50,\n",
    "#                                           shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self, d=128, K=11):\n",
    "        super(Network, self).__init__()\n",
    "        self.K = K\n",
    "        self.init_net(d)\n",
    "    \n",
    "    # initializers\n",
    "    def init_net(self, d):\n",
    "        self.conv1 = nn.Conv2d(1, d, 4, 2, 1)\n",
    "        self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(d*2)\n",
    "        self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(d*4)\n",
    "#         self.conv4 = nn.Conv2d(d*4, 1, 4, 1, 0)\n",
    "        self.fc1 = nn.Linear(576, 50)\n",
    "        self.fc1_drop = nn.Dropout()\n",
    "        self.fc2 = nn.Linear(50, self.K)\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, input):\n",
    "        x = F.relu(self.conv1(input))\n",
    "        x = F.relu(self.conv2_bn(self.conv2(x)))\n",
    "        x = F.relu(self.conv3_bn(self.conv3(x)))\n",
    "#         x = F.relu(self.conv4(x))\n",
    "#         print(x.size())\n",
    "        x = x.view(-1, 576)\n",
    "#         print(x.size())\n",
    "        x = self.fc1_drop(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "#         x = F.softmax(self.fc2(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SemiClassifier():\n",
    "    \n",
    "    def __init__(self, net, lr=0.01):#, unlabeled_ds=None, semi=True, labeled_ds, ):\n",
    "        self.net = net\n",
    "        self._init_optimizer(lr)\n",
    "    \n",
    "    def loss(self, x_l, y_l, x_u=None):\n",
    "        \n",
    "        d_l = self.net.forward(x_l)\n",
    "            \n",
    "        ce = nn.NLLLoss()\n",
    "        l_loss = ce(torch.log(d_l), y_l)\n",
    "        loss = l_loss\n",
    "        if x_u is not None:\n",
    "            d_u = self.net.forward(x_u)\n",
    "#             max_probs = torch.max(torch.log(d_u), 1)[0]\n",
    "#             u_loss = torch.mean(-max_probs) / 10\n",
    "#             loss += u_loss\n",
    "            loss += -torch.sum(d_u * torch.log(d_u)) / 10\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    \n",
    "    def _init_optimizer(self, lr):\n",
    "        self.optimizer = optim.Adam(self.net.parameters(),\n",
    "                lr=lr, betas=(0.5, 0.999))\n",
    "        \n",
    "    def step(self, x_l, y_l, x_u=None):\n",
    "        \n",
    "        self.net.zero_grad()\n",
    "        loss = self.loss(x_l, y_l, x_u)   \n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.data.numpy()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return self.net.forward(x)\n",
    "    \n",
    "    \n",
    "# class GANBasedClassifier():\n",
    "    \n",
    "#     def __init__(self, net, lr=0.01):#, unlabeled_ds=None, semi=True, labeled_ds, ):\n",
    "#         self.net = net\n",
    "#         self._init_optimizer(lr)\n",
    "    \n",
    "#     def loss(self, x_l, y_l, x_u=None, z=None):\n",
    "        \n",
    "#         d_l = self.net.forward(x_l)\n",
    "            \n",
    "#         ce = nn.NLLLoss()\n",
    "#         l_loss = ce(d_l, y_l)\n",
    "#         loss = l_loss\n",
    "#         if x_u is not None:\n",
    "#             d_u = self.net.forward(x_u)\n",
    "#             probs = F.softmax(d_u)\n",
    "#             sum_probs = torch.sum(probs, 1)[:-1] # Right?\n",
    "#             u_loss = -torch.mean(torch.log(sum_probs))\n",
    "#             loss += u_loss\n",
    "# #             loss += -torch.sum(d_u * torch.log(d_u)) / 10\n",
    "\n",
    "#         if z is not None:\n",
    "#             d_z = self.net.forward(z)\n",
    "# #             d_z = self.net.forward_last_layers(z)\n",
    "#             z_vals = torch.ones(z.size()[0]) * (self.net.K-1)\n",
    "#             z_vals = Variable(z_vals, requires_grad=False).long()\n",
    "#             z_loss = ce(d_z, z_vals)\n",
    "#             loss += z_loss\n",
    "        \n",
    "#         return loss\n",
    "        \n",
    "    \n",
    "#     def _init_optimizer(self, lr):\n",
    "#         self.optimizer = optim.Adam(self.net.parameters(),\n",
    "#                 lr=lr, betas=(0.5, 0.999))\n",
    "        \n",
    "#     def step(self, x_l, y_l, x_u=None, z=None):\n",
    "        \n",
    "#         self.net.zero_grad()\n",
    "#         loss = self.loss(x_l, y_l, x_u, z)   \n",
    "#         loss.backward()\n",
    "#         self.optimizer.step()\n",
    "#         return loss.data.numpy()\n",
    "        \n",
    "#     def predict(self, x):\n",
    "#         return F.softmax(self.net.forward(x))\n",
    "\n",
    "class GANBasedClassifier():\n",
    "    \n",
    "    def __init__(self, net, lr=0.01):#, unlabeled_ds=None, semi=True, labeled_ds, ):\n",
    "        self.net = net\n",
    "        self._init_optimizer(lr)\n",
    "    \n",
    "    def loss(self, x_l, y_l, x_u=None, z=None):\n",
    "        \n",
    "        stability_fix = 1e-8\n",
    "        d_l = self.net.forward(x_l)\n",
    "            \n",
    "        ce = nn.CrossEntropyLoss()\n",
    "        l_loss = ce(d_l, y_l)\n",
    "        loss = l_loss\n",
    "        if x_u is not None:\n",
    "            d_u = self.net.forward(x_u)\n",
    "            probs_u = F.softmax(d_u)\n",
    "            sum_probs = torch.sum(probs_u, 1)[:-1] # Right?\n",
    "            u_loss = -torch.mean(torch.log(sum_probs + stability_fix))\n",
    "            loss += u_loss\n",
    "            loss += -torch.mean(torch.sum(probs_u * torch.log(probs_u + stability_fix), 1))\n",
    "            \n",
    "\n",
    "        if z is not None:\n",
    "            d_z = self.net.forward(z)\n",
    "#             d_z = self.softmax(dz)\n",
    "            z_vals = torch.ones(z.size()[0]) * (self.net.K-1)\n",
    "            z_vals = Variable(z_vals, requires_grad=False).long()\n",
    "            z_loss = ce(d_z, z_vals) / 3\n",
    "            loss += z_loss\n",
    "#         print(loss)\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    \n",
    "    def _init_optimizer(self, lr):\n",
    "        self.optimizer = optim.Adam(self.net.parameters(),\n",
    "                lr=lr, betas=(0.5, 0.999))\n",
    "        \n",
    "    def step(self, x_l, y_l, x_u=None, z=None):\n",
    "        \n",
    "        self.net.zero_grad()\n",
    "        loss = self.loss(x_l, y_l, x_u, z)   \n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.data.numpy()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        d = self.net.forward(x)\n",
    "        return F.softmax(d)\n",
    "    \n",
    "    \n",
    "    \n",
    "def make_z_gen(batch_size):\n",
    "    while True:\n",
    "        z = 2 * (np.random.rand(batch_size, 50))#.reshape([batch_size, 1, 28, 28])\n",
    "        z = torch.from_numpy(z).float()\n",
    "        yield Variable(z, requires_grad=False)\n",
    "        \n",
    "def make_z_gen_from_unlabeled(batch_size, dataset):\n",
    "    ds_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "            shuffle=True, num_workers=2)\n",
    "    while True:\n",
    "        for batch in ds_loader:\n",
    "            z = .2 * (np.random.rand(batch.size()[0], 784) - 0.5).reshape([batch.size()[0], 1, 28, 28])\n",
    "#             z = torch.from_numpy(z).float()\n",
    "#             z = Variable(z, requires_grad=False)\n",
    "\n",
    "#             x = np.flip(batch.numpy(), axis=2).copy()\n",
    "#             x = torch.from_numpy(x).float()\n",
    "#             x = batch.permute(0, 1, 3, 2)\n",
    "#             x = Variable(x, requires_grad=False)\n",
    "\n",
    "            x = batch.numpy()\n",
    "            x = (x + x[::-1])/2\n",
    "            x = x + z\n",
    "            x = Variable(torch.from_numpy(x), requires_grad=False).float()\n",
    "    \n",
    "#             x[x > 1.] = 1.\n",
    "#             x[x < 0.] = 0.\n",
    "            yield x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = Network(d=16, K=11)\n",
    "net.apply(weights_init)\n",
    "model_gan = GANBasedClassifier(net, lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled_gen = make_batch_generator(labeled, 50)\n",
    "unlabeled_gen = make_batch_generator(unlabeled, 50)\n",
    "# z_gen = make_z_gen(50)\n",
    "z_gen = make_z_gen_from_unlabeled(50, unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 [ 4.42813921]\n",
      "200 [ 2.09346628]\n",
      "300 [ 0.95730448]\n",
      "400 [ 0.54751623]\n",
      "500 [ 0.42088097]\n",
      "\tAccuracy: 0.9411\n",
      "600 [ 0.32764041]\n",
      "700 [ 0.27498817]\n",
      "800 [ 0.2449342]\n",
      "900 [ 0.19954516]\n",
      "1000 [ 0.18866451]\n",
      "\tAccuracy: 0.9576\n",
      "1100 [ 0.17002305]\n",
      "1200 [ 0.14594945]\n",
      "1300 [ 0.13555263]\n",
      "1400 [ 0.12035219]\n",
      "1500 [ 0.1015581]\n",
      "\tAccuracy: 0.9642\n",
      "1600 [ 0.10086226]\n",
      "1700 [ 0.09929861]\n",
      "1800 [ 0.09625833]\n",
      "1900 [ 0.08331797]\n",
      "2000 [ 0.07635426]\n",
      "\tAccuracy: 0.9668\n",
      "2100 [ 0.07596937]\n",
      "2200 [ 0.07207195]\n",
      "2300 [ 0.07191485]\n",
      "2400 [ 0.07681382]\n",
      "2500 [ 0.06966086]\n",
      "\tAccuracy: 0.9692\n",
      "2600 [ 0.06900261]\n",
      "2700 [ 0.05323553]\n",
      "2800 [ 0.06887281]\n",
      "2900 [ 0.05646901]\n",
      "3000 [ 0.05872469]\n",
      "\tAccuracy: 0.9697\n",
      "3100 [ 0.05031718]\n",
      "3200 [ 0.06150445]\n",
      "3300 [ 0.05303931]\n",
      "3400 [ 0.05745563]\n",
      "3500 [ 0.05529197]\n",
      "\tAccuracy: 0.9663\n",
      "3600 [ 0.06106005]\n",
      "3700 [ 0.0511173]\n",
      "3800 [ 0.04475059]\n",
      "3900 [ 0.03839761]\n",
      "4000 [ 0.04638686]\n",
      "\tAccuracy: 0.9721\n",
      "4100 [ 0.03655483]\n",
      "4200 [ 0.04608806]\n",
      "4300 [ 0.03989833]\n",
      "4400 [ 0.04335951]\n",
      "4500 [ 0.04302717]\n",
      "\tAccuracy: 0.9688\n",
      "4600 [ 0.04039812]\n",
      "4700 [ 0.03688509]\n",
      "4800 [ 0.04076854]\n",
      "4900 [ 0.04036387]\n",
      "5000 [ 0.04649028]\n",
      "\tAccuracy: 0.9696\n",
      "5100 [ 0.03908983]\n",
      "5200 [ 0.04431253]\n",
      "5300 [ 0.03134542]\n",
      "5400 [ 0.03631483]\n",
      "5500 [ 0.03819665]\n",
      "\tAccuracy: 0.9713\n",
      "5600 [ 0.03166588]\n",
      "5700 [ 0.02815685]\n",
      "5800 [ 0.03316586]\n",
      "5900 [ 0.03560093]\n",
      "6000 [ 0.03520999]\n",
      "\tAccuracy: 0.9735\n",
      "6100 [ 0.03652541]\n",
      "6200 [ 0.0400555]\n",
      "6300 [ 0.04048484]\n",
      "6400 [ 0.03131305]\n",
      "6500 [ 0.03620369]\n",
      "\tAccuracy: 0.9711\n",
      "6600 [ 0.03567539]\n",
      "6700 [ 0.0274306]\n",
      "6800 [ 0.02890081]\n",
      "6900 [ 0.09368383]\n",
      "7000 [ 0.03914329]\n",
      "\tAccuracy: 0.9716\n",
      "7100 [ 0.03004789]\n",
      "7200 [ 0.02883238]\n",
      "7300 [ 0.03395713]\n",
      "7400 [ 0.02489742]\n",
      "7500 [ 0.03177691]\n",
      "\tAccuracy: 0.9745\n",
      "7600 [ 0.02553651]\n",
      "7700 [ 0.02793221]\n",
      "7800 [ 0.03337718]\n",
      "7900 [ 0.02875894]\n",
      "8000 [ 0.03147463]\n",
      "\tAccuracy: 0.9731\n",
      "8100 [ 0.02598453]\n",
      "8200 [ 0.02052615]\n",
      "8300 [ 0.02531775]\n",
      "8400 [ 0.02794501]\n",
      "8500 [ 0.02588562]\n",
      "\tAccuracy: 0.9717\n",
      "8600 [ 0.0234992]\n",
      "8700 [ 0.02791191]\n",
      "8800 [ 0.02960804]\n",
      "8900 [ 0.02291116]\n",
      "9000 [ 0.02360997]\n",
      "\tAccuracy: 0.9734\n",
      "9100 [ 0.03667176]\n",
      "9200 [ 0.03007953]\n",
      "9300 [ 0.02813987]\n",
      "9400 [ 0.03375286]\n",
      "9500 [ 0.02697914]\n",
      "\tAccuracy: 0.9758\n",
      "9600 [ 0.02883635]\n",
      "9700 [ 0.0335808]\n",
      "9800 [ 0.02527324]\n",
      "9900 [ 0.02727813]\n",
      "10000 [ 0.03860689]\n",
      "\tAccuracy: 0.9733\n",
      "10100 [ 0.02394537]\n",
      "10200 [ 0.0313808]\n",
      "10300 [ 0.02935293]\n",
      "10400 [ 0.02532506]\n",
      "10500 [ 0.02657978]\n",
      "\tAccuracy: 0.9746\n",
      "10600 [ 0.01922546]\n",
      "10700 [ 0.02731616]\n",
      "10800 [ 0.02572876]\n",
      "10900 [ 0.03595162]\n",
      "11000 [ 0.02689439]\n",
      "\tAccuracy: 0.9753\n",
      "11100 [ 0.02396475]\n",
      "11200 [ 0.02138016]\n",
      "11300 [ 0.02105777]\n",
      "11400 [ 0.02325884]\n",
      "11500 [ 0.0283803]\n",
      "\tAccuracy: 0.9741\n",
      "11600 [ 0.02420804]\n",
      "11700 [ 0.02828314]\n",
      "11800 [ 0.01722974]\n",
      "11900 [ 0.02430572]\n",
      "12000 [ 0.0246806]\n",
      "\tAccuracy: 0.9768\n",
      "12100 [ 0.01896866]\n",
      "12200 [ 0.0241469]\n",
      "12300 [ 0.02928369]\n",
      "12400 [ 0.02394482]\n",
      "12500 [ 0.01589432]\n",
      "\tAccuracy: 0.9747\n",
      "12600 [ 0.01987803]\n",
      "12700 [ 0.02261625]\n",
      "12800 [ 0.02072463]\n",
      "12900 [ 0.02187901]\n",
      "13000 [ 0.01966264]\n",
      "\tAccuracy: 0.9715\n",
      "13100 [ 0.018824]\n",
      "13200 [ 0.02395673]\n",
      "13300 [ 0.02471312]\n",
      "13400 [ 0.01674996]\n",
      "13500 [ 0.02140173]\n",
      "\tAccuracy: 0.9737\n",
      "13600 [ 0.03573465]\n",
      "13700 [ 0.0203029]\n",
      "13800 [ 0.0230131]\n",
      "13900 [ 0.02325007]\n",
      "14000 [ 0.02033461]\n",
      "\tAccuracy: 0.9737\n",
      "14100 [ 0.01832654]\n",
      "14200 [ 0.03088563]\n",
      "14300 [ 0.02725243]\n",
      "14400 [ 0.02131092]\n",
      "14500 [ 0.02299692]\n",
      "\tAccuracy: 0.9769\n",
      "14600 [ 0.0207332]\n",
      "14700 [ 0.0220082]\n",
      "14800 [ 0.02514557]\n",
      "14900 [ 0.02088603]\n",
      "15000 [ 0.02084173]\n",
      "\tAccuracy: 0.9733\n",
      "15100 [ 0.02422806]\n",
      "15200 [ 0.02213261]\n",
      "15300 [ 0.01823894]\n",
      "15400 [ 0.01607012]\n",
      "15500 [ 0.02091909]\n",
      "\tAccuracy: 0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-437:\n",
      "Process Process-445:\n",
      "Process Process-438:\n",
      "Process Process-440:\n",
      "Process Process-446:\n",
      "Process Process-439:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-90183a10cd6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpreds_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\tAccuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpreds_class\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_gan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mmean_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-e4eaa6b864bd>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, x_l, y_l, x_u, z)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mean_loss = 0\n",
    "t = 0\n",
    "\n",
    "for i in range(20000):\n",
    "    x_l, y_l = next(labeled_gen)\n",
    "    x_u = next(unlabeled_gen)\n",
    "    z = next(z_gen)\n",
    "    \n",
    "    if not ((i+1) % 100):\n",
    "        print(i+1, mean_loss/t)\n",
    "        mean_loss = 0\n",
    "        t = 0\n",
    "        \n",
    "    if not((i+1) % 500):\n",
    "        preds_prob = model_gan.predict(Variable(x_test)).data.numpy()[:, :-1]\n",
    "        preds_class = np.argmax(preds_prob, axis=1)\n",
    "        print('\\tAccuracy:', np.sum(y_test == preds_class) / y_test.shape[0])\n",
    "    loss = model_gan.step(x_l, y_l, x_u, z)\n",
    "    mean_loss += loss\n",
    "    t += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = next(z_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs = z.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1, 14, 28])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:, :, ::2].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1144f4550>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114498ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imgs[4, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_class[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_test == preds_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAccuracy: 0.098\n"
     ]
    }
   ],
   "source": [
    "preds_prob = model_gan.predict(Variable(x_test)).data.numpy()[:, :-1]\n",
    "preds_class = np.argmax(preds_prob, axis=1)\n",
    "print('\\tAccuracy:', np.sum(y_test == preds_class) / y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net_sup = Network(d=16, K=10)\n",
    "net_sup.apply(weights_init)\n",
    "model_sup = SemiClassifier(net_sup, lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled_gen = make_batch_generator(labeled, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 [ 0.03584554]\n",
      "199 [ 0.02163391]\n",
      "299 [ 0.03043898]\n",
      "399 [ 0.02567868]\n",
      "499 [ 0.01260155]\n",
      "\tAccuracy: 0.9872\n",
      "599 [ 0.01504184]\n",
      "699 [ 0.00961216]\n",
      "799 [ 0.00618663]\n",
      "899 [ 0.01370139]\n",
      "999 [ 0.01684636]\n",
      "\tAccuracy: 0.9861\n",
      "1099 [ 0.0221732]\n",
      "1199 [ 0.01092714]\n",
      "1299 [ 0.00775784]\n",
      "1399 [ 0.0182983]\n",
      "1499 [ 0.00542831]\n",
      "\tAccuracy: 0.9867\n",
      "1599 [ 0.00752426]\n",
      "1699 [ 0.00876954]\n",
      "1799 [ 0.02434348]\n",
      "1899 [ 0.01653739]\n",
      "1999 [ 0.01294875]\n",
      "\tAccuracy: 0.9838\n",
      "2099 [ 0.01907762]\n",
      "2199 [ 0.02272564]\n",
      "2299 [ 0.02949499]\n",
      "2399 [ 0.01829935]\n",
      "2499 [ 0.01886867]\n",
      "\tAccuracy: 0.9869\n",
      "2599 [ 0.01408803]\n",
      "2699 [ 0.01484888]\n",
      "2799 [ 0.00935343]\n",
      "2899 [ 0.01319065]\n",
      "2999 [ 0.00892878]\n",
      "\tAccuracy: 0.9882\n",
      "3099 [ 0.01920759]\n",
      "3199 [ 0.01908769]\n",
      "3299 [ 0.01703345]\n",
      "3399 [ 0.01535782]\n",
      "3499 [ 0.01732407]\n",
      "\tAccuracy: 0.9873\n",
      "3599 [ 0.01383578]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-42:\n",
      "Process Process-41:\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-edc317050bfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mpreds_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\tAccuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpreds_class\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mloss_sup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_sup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mmean_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_sup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-e90ded7ec55d>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, x_l, y_l, x_u)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_u\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n"
     ]
    }
   ],
   "source": [
    "mean_loss = 0\n",
    "t = 0\n",
    "for i in range(5000):\n",
    "    x_l, y_l = next(labeled_gen)\n",
    "    if not ((i+1) % 100):\n",
    "        print(i, mean_loss/t)\n",
    "        mean_loss = 0\n",
    "        t = 0\n",
    "    if not((i+1) % 500):\n",
    "        preds_prob = model_sup.predict(Variable(x_test)).data.numpy()\n",
    "        preds_class = np.argmax(preds_prob, axis=1)\n",
    "        print('\\tAccuracy:', np.sum(y_test == preds_class) / y_test.shape[0])\n",
    "    loss_sup = model_sup.step(x_l, y_l)\n",
    "    mean_loss += loss_sup\n",
    "    t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_prob = model_sup.predict(Variable(x_test)).data.numpy()\n",
    "preds_class = np.argmax(preds_prob, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net_semi = Network(10)\n",
    "net_semi.apply(weights_init)\n",
    "model_semi = SemiClassifier(net_semi, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled_gen = make_batch_generator(labeled, 50)\n",
    "unlabeled_gen = make_batch_generator(unlabeled, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def make_random_gen(batch_size, shape=50):\n",
    "#     while True:\n",
    "#         z = np.random.rand(batch_size, shape)* 2 - 1\n",
    "#         return Variable(z, requires_grad=False).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 [ 1.69764185]\n",
      "200 [ 1.15048254]\n",
      "300 [ 1.04159737]\n",
      "400 [ 1.01232195]\n",
      "500 [ 0.91960853]\n",
      "\tAccuracy: 0.9171\n",
      "600 [ 0.81323296]\n",
      "700 [ 0.8691057]\n",
      "800 [ 0.81949717]\n",
      "900 [ 0.80083632]\n",
      "1000 [ 0.79485357]\n",
      "\tAccuracy: 0.9313\n",
      "1100 [ 0.77135831]\n",
      "1200 [ 0.7276867]\n",
      "1300 [ 0.7102173]\n",
      "1400 [ 0.71404135]\n",
      "1500 [ 0.68416327]\n",
      "\tAccuracy: 0.9233\n",
      "1600 [ 0.7508902]\n",
      "1700 [ 0.73940122]\n",
      "1800 [ 0.7443341]\n",
      "1900 [ 0.72703522]\n",
      "2000 [ 0.68475431]\n",
      "\tAccuracy: 0.933\n",
      "2100 [ 0.65783495]\n",
      "2200 [ 0.74128538]\n",
      "2300 [ 0.74749136]\n",
      "2400 [ 0.7388925]\n",
      "2500 [ 0.71143442]\n",
      "\tAccuracy: 0.9358\n",
      "2600 [ 0.68153191]\n",
      "2700 [ 0.69175285]\n",
      "2800 [ 0.68161893]\n",
      "2900 [ 0.73074555]\n",
      "3000 [ 0.644777]\n",
      "\tAccuracy: 0.9342\n",
      "3100 [ 0.70305097]\n",
      "3200 [ 0.72644961]\n",
      "3300 [ 0.76000029]\n",
      "3400 [ 0.64694488]\n",
      "3500 [ 0.68373251]\n",
      "\tAccuracy: 0.938\n",
      "3600 [ 0.60520154]\n",
      "3700 [ 0.6878565]\n",
      "3800 [ 0.71089464]\n",
      "3900 [ 0.69952399]\n",
      "4000 [ 0.64404511]\n",
      "\tAccuracy: 0.9311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-167:\n",
      "Process Process-179:\n",
      "Process Process-180:\n",
      "Process Process-168:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-9d016a651dc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpreds_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\tAccuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpreds_class\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_semi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_u\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mmean_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-a555363bba86>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, x_l, y_l, x_u)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_u\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "mean_loss = 0\n",
    "t = 0\n",
    "for i in range(5000):\n",
    "    x_l, y_l = next(labeled_gen)\n",
    "    x_u = next(unlabeled_gen)\n",
    "    if not ((i+1) % 100):\n",
    "        print(i+1, mean_loss/t)\n",
    "        mean_loss = 0\n",
    "        t = 0\n",
    "    if not((i+1) % 500):\n",
    "        preds_prob = model_semi.predict(Variable(x_test)).data.numpy()\n",
    "        preds_class = np.argmax(preds_prob, axis=1)\n",
    "        print('\\tAccuracy:', np.sum(y_test == preds_class) / y_test.shape[0])\n",
    "    loss = model_semi.step(x_l, y_l, x_u)\n",
    "    mean_loss += loss\n",
    "    t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
